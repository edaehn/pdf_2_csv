#!/usr/bin/python
# -*- coding: utf-8 -*-
"""Saving the PDF file Srape.pdf with table into CSV format. 

This script demonstrates two methods of converting a table 
extracted from the Scrape.pdf file into a CSV file.
For creating these methods we exploit PyPDF2 and tabula.
We will see which method is the best by measuring their execution time.
Finally, with the help of Pandads DataFrame we check if both CSV outputs do match.

Input:  The script expects Scrape.pdf to be in the same directory
Output: The script saves CSV files (tabula_Scrape.csv and PyPDF2_Scrape.csv) 
generated by both methods in the same directory. The execution time performance results 
are shown on screen.

Dependencies: 
1. pip install PyPDF2
2. pip install tabula-py

Running:
python pdf_to_csv.py
"""
import os, sys, time
import PyPDF2
from tabula import convert_into
import pandas as pd
import numpy as np

# we expect to find Scrape.pdf in the current directory
input_file='Scrape.pdf'
output_file='Scrape.csv'

# We check if Scrape.pdf is in the same directory
if not os.path.isfile(input_file):
	print "File Scrape.pdf is not in this directory. \nPlease try again after storing Scrape.pdf into the %s directory. "%os.path.dirname(os.path.abspath(__file__))
	sys.exit(0) # we cannot see it here, so we exit
	
# Variables to hold the output strings
separator="=================================================" # lines separator in the script output
result_output="\n"+separator+"\nExtracting the PDF table into the CSV format\n"+separator # to show the script output in the end of the script


################################## Method 1. Easiest
start_time = time.time() # we want to find which method is the quickest with time
# Using convert_into with all pages option, which store the whole PDF table into CSV
convert_into(input_file, "tabula_"+output_file, output_format="csv", pages="all")
time1=round(time.time() - start_time,2) # we keep the execution time in time1 to be compared
result_output+="\n%s: \t%s seconds" % ("Using tabula-py", time1)


################################## Method 2. Fastest (~x3 times)
start_time = time.time()
reader=PyPDF2.PdfFileReader(open(input_file, "rb")) # reading the PDF file
num_pages=reader.getNumPages() # getting the number of pages
# Extracting text from all PDF pages into the text string
text=" ".join([reader.getPage(page).extractText() for page in range(0, num_pages)])

# We know the table header when we look into the text
header=[u'COUNTRY CODE', u'NAME', u'ADDRESS', u'ZIP CODE', u'CITY', u'DESCRIPTION']

# Next, if not using encode to utf-8, we will get the 
# UnicodeEncodeError: 'ascii' codec can't encode character u'\xe9'
# We also split text elements by the carriage return
text_elements=text.encode('utf-8').split('\n') 

# We store each table row (except of the header, this is why we start from the
# header_len*2 position) into the array rows
rows=[]
header_len=len(header) # number of columns in the PDF table
for index in range(header_len*2, len(text_elements),header_len):
	rows.append(text_elements[index-header_len:index])

# Herein we strip off the heading and trailing spaces, and save it into the CSV file	
pd.DataFrame(columns=header, data=rows).applymap(lambda x: x.strip()).\
	to_csv("PyPDF2_"+output_file, index=False)
# if we use following, we get 13 different rows (see different_test.csv) since there are 
# some trailing and heading spaces occur
# pd.DataFrame(columns=header, data=rows).to_csv("PyPDF2_"+output_file, index=False)

time2=round(time.time() - start_time,) # we keep the execution time in time2

# We mark the quickest method in the output table
if time2>time1:
	result_output+="\tquickest"
	result_output+="\n%s: \t\t%s seconds" % ("Using PyPDF2", time2)
else:
	result_output+="\n%s: \t\t%s seconds\tquickest" % ("Using PyPDF2", time2)

result_output+="\n"+separator


###################  Testing if both CSV are the same

df_tabula=pd.read_csv("tabula_"+output_file, encoding="utf-8")
df_PyPDF2=pd.read_csv("PyPDF2_"+output_file, encoding="utf-8")

# Testing if dataframes are different with indexing
different = df_tabula.index[np.any(df_tabula != df_PyPDF2,axis=1)]
if len(different):   
	# we store the different rows into one dataframe "df_different"  
	# we thus concatenate the both dataframes on different rows, side-by-side              
	df_different = pd.concat([df_tabula.iloc[different], df_PyPDF2.iloc[different]], \
		axis='columns', keys=['tabula', 'PyPDF2'])
	result_output+="\nWe found that %d rows are different in both tables"% \
		df_different.shape[0]
	
	# We keep the same columns close-by
	df_different=df_different.swaplevel(axis=1)[df_tabula.columns] 
	# We rotate the dataframe to show it better on screen
	result_output+="\n"+str(df_different.T) 
else:
	result_output+="\nBoth CSV outputs (see files %s \nand %s) are identical."%\
		("tabula_"+output_file,"PyPDF2_"+output_file)

# Printing the results
result_output+="\n%s \nThank you."%separator
print result_output
